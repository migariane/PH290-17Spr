These instructions are for use on bash shell (e.g., running in terminal or VirtualBox on your laptop). You can run the Spark EC2 script from your own laptop but you may need to figure some things out on your own. However I expect these instructions may well work just fine for Macs.

0) As noted in (7) below, it's important that you delete your cluster when you're not actively using it. Don't leave it running overnight or while you go off for a few hours, as you'll incur much fees for your account.

1) To download Spark, go to https://spark.apache.org/downloads.html, choose
* 1.5.1
* source code
* direct download

Click on link in #4 entry. Download to the VM and untar/zip the file.

2) Create UNIX environment variables containing your AWS credentials based on your own .boto file:

export AWS_ACCESS_KEY_ID=`grep aws_access_key_id wilson.boto | cut -d' ' -f3`
export AWS_SECRET_ACCESS_KEY=`grep aws_secret_access_key wilson.boto | cut -d' ' -f3`

3) Put your private SSH key file on the VM, ideally in ~/.ssh. Change permissions on the file:
chmod 400 ~/.ssh/wilson-ssh.pem

4) Navigate to spark-1.5.1/ec2 and start a spark cluster, specifying the number of worker nodes you want in your Spark cluster. When first experimenting at getting a cluster going, just use a few workers but for the problem set, try using 112 workers.
export NUMBER_OF_WORKERS=3
./spark-ec2 -k <your-aws-key-pair> -i ~/.ssh/wilson-ssh.pem --region=us-west-2 -s ${NUMBER_OF_WORKERS} -v 1.5.1 launch sparkvm-<your_aws_username>

Occasionally you'll get some error messages and things won't start up correctly.  Just kill the cluster and try again. You might increase the number after the "-w" to increase the wait time that the Spark script uses to allow the Amazon instances to start up.

5) Once it has finished (it will take 10-20 minutes), you can login as follows:
./spark-ec2 -k <your-aws-key-pair> -i wilson-ssh.pem --region=us-west-2 login sparkvm-<your_aws_username>

6) Now you can follow the template provided in the Workshop notes to use Spark

Note that the airline data can be obtained (once you login to the master node) via:
wget http://www.stat.berkeley.edu/share/paciorek/1987-2008.csvs.tgz
tar -xvzf 1987-2008.csvs.tgz

6a) If you experience problems where the connection to your master instance gets cut off, this may be interruption due to a bad wireless connection. Here's something that can help. As soon as you login to your instance, type "screen -x -RR". This will put you in a shell session that you'll be able to go back to even if you lose your connection. If you lose the connection, then when you connect back to the master node, type "screen -x -RR" again and you should be back where you were. If you were in Python, you may need to hit return once or twice to get the Python prompt back.

7) IMPORTANT: delete your cluster as soon as you are done with it. We only have a limited number of credits for everyone in the class to use.

./spark-ec2 --region=us-west-2 --delete-groups destroy sparkvm-<your_aws_username>
